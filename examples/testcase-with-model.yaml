# youBencha Test Case with Model Selection
# This example shows how to specify the model for copilot CLI

# Test case metadata
name: "Add friendly welcome message to README with specific model"
description: "Tests the agent's ability to add a friendly welcome message to the README file using a specific model"

# Repository configuration (test data)
repo: https://github.com/youbencha/hello-world.git
branch: main

# Agent configuration - what coding agent to use and what to ask it
agent:
  type: copilot-cli  # Currently the only supported agent
  model: gpt-5.1  # Optional: Specify which model to use
  # Available models:
  #   - claude-sonnet-4.5
  #   - claude-sonnet-4
  #   - claude-haiku-4.5
  #   - gpt-5
  #   - gpt-5.1
  #   - gpt-5.1-codex-mini
  #   - gpt-5.1-codex
  #   - gemini-3-pro-preview
  config:
    prompt: "Add a friendly welcome message to the README file"

# Evaluators - run checks and generate assertions about the code
evaluators:
  # git-diff: Measures the scope of changes (files changed, lines added/removed)
  - name: git-diff
  
  # agentic-judge: Uses AI to evaluate quality based on assertions
  - name: agentic-judge
    config:
      type: copilot-cli
      agent_name: agentic-judge  # Uses the built-in evaluation agent
      model: claude-sonnet-4.5  # Optional: Use a different model for evaluation
      
      # Define explicit pass/fail assertions (keys become metric names in the report)
      assertions:
        readme_was_modified: "The README.md file was modified. Score 1 if true, 0 if false."
        message_is_friendly: "A friendly welcome message was added. Score 1 if friendly, 0.5 if neutral, 0 if absent or unfriendly."
        no_errors: "No syntax errors or broken markdown. Score 1 if valid, 0 if broken."
